{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow:实战Google深度学习框架学习笔记"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# TensorFlow声明一个矩阵变量的方法\n",
    "weights = tf.Variable(tf.random_normal([2,3],stddev = 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow 随机数生成函数\n",
    "|函数名称|随机数分布|主要参数|\n",
    "|----|:----:|:----:|\n",
    "|tf.random_normal|正态分布|平均值，标准差，取值类型|\n",
    "|tf.truncated_normal|正态分布，但如果选出来的随机数均值超过两个标准差|平均值，标准差，取值类型|\n",
    "|tf.random_uniform|均匀分布|最大，最小取值，取值类型|\n",
    "|tf.random_gamma|Gamma分布|形状参数alpha,尺度参数beta,取值类型|\n",
    "\n",
    "### TensorFlow常数生成函数/类似于numpy\n",
    "|函数名称|功能|样例|\n",
    "|:--:|:--:|:--:|\n",
    "|tf.zeros|产生全0的数组|tf.zeros([2,3],int32) -> [[0,0,0],[0,0,0]]|\n",
    "|tf.ones|产生全1的数组|tf.ones([2,3],int32) -> [[1,1,1],[1,1,1]]|\n",
    "|tf.fill|产生全部为给定数字的数组|tf.fill([2,3],9) -> [[9,9,9],[9,9,9]]|\n",
    "|tf.constant|产生一个给定值的常量|tf.constant([1,2,3]) -> [1,2,3]|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 偏置项一般用常数来设置,[0,0,0]\n",
    "biases = tf.Variable(tf.zeros([3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# w2的初始值与weights相同的变量\n",
    "# w3的初始值是weights的二倍\n",
    "w2 = tf.Variable(weights.initialized_value())\n",
    "w3 = tf.Variable(weights.initialized_value() * 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.95757794]]\n"
     ]
    }
   ],
   "source": [
    "# 通过变量实现神经网络参数并实现向前传播的过程\n",
    "# 声明w1,w2两个变量。\n",
    "w1 = tf.Variable(tf.random_normal((2,3), stddev = 1, seed = 1))\n",
    "w2 = tf.Variable(tf.random_normal((3,1), stddev = 1, seed = 1))\n",
    "\n",
    "# 暂时将输入的特征向量定义为一个常量。x是一个1*2的矩阵。\n",
    "x = tf.constant([[0.7,0.9]])\n",
    "\n",
    "#通过前向传播算法获得神经网络输出\n",
    "\n",
    "a = tf.matmul(x, w1)\n",
    "y = tf.matmul(a, w2)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(w1.initializer)  #初始化w1\n",
    "sess.run(w2.initializer)   #初始化w2\n",
    "print(sess.run(y))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#初始化所有变量\n",
    "sess = tf.Session()\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess.run(init_op)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow中的变量\n",
    "变量是一种特殊的张量  \n",
    "TensorFlow中所有的变量会被加入GraphKeys.VARIABLES集合中。\n",
    "trainable参数用来区分需要优化的参数。\n",
    "- trainable为True,变量为需要优化的参数。这个变量会被加入到GraphKeys.TRAINABLE_VARIABLES集合。\n",
    "\n",
    "维度和类型是变量的最重要的两个属性。\n",
    "- 变量的类型是不可以改变的\n",
    "- 变量的维度是可以改变的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n程序会报错：类型不匹配。\\nTypeError: Input 'value' of 'Assign' Op has type float64 that does not match type float32 of argument 'ref'.\\n\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1  = tf.Variable(tf.random_normal([2,3],stddev = 1), name = \"w1\")\n",
    "#w2 = tf.Variable(tf.random_normal([2,3],dtype = tf.float64, stddev = 1),name = \"w2\")\n",
    "#w1.assign(w2)\n",
    "\n",
    "'''\n",
    "程序会报错：类型不匹配。\n",
    "TypeError: Input 'value' of 'Assign' Op has type float64 that does not match type float32 of argument 'ref'.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Assign_2:0' shape=(2, 2) dtype=float32_ref>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = tf.Variable(tf.random_normal([2,3], stddev = 1), name = \"w1\")\n",
    "w2 = tf.Variable(tf.random_normal([2,2], stddev = 1), name = \"w2\")\n",
    "#下面这句会报维度不匹配\n",
    "'''\n",
    "ValueError: Dimension 1 in both shapes must be equal, but are 3 and 2 for 'Assign_1' (op: 'Assign') with input shapes: [2,3], [2,2].\n",
    "'''\n",
    "# tf.assign(w1,w2)\n",
    "#这一句可以被成功执行\n",
    "tf.assign(w1, w2, validate_shape = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 通过TensorFlow训练神经网络模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.95757794]\n",
      " [ 1.15376544]\n",
      " [ 3.16749239]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n输出：\\n[[ 3.95757794]\\n [ 1.15376544]\\n [ 3.16749239]]\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 通过placeholder实现前向传播算法\n",
    "w1 = tf.Variable(tf.random_normal([2,3], stddev = 1, seed = 1))\n",
    "w2 = tf.Variable(tf.random_normal([3,1], stddev = 1, seed = 1))\n",
    "\n",
    "#定义placeholder作为存放输入数据的地方。不一定要定义维度。\n",
    "#但如果维度确定的，那么给出维度可以降低出错率\n",
    "x = tf.placeholder(tf.float32, shape = (3,2), name = \"input\")\n",
    "a = tf.matmul(x, w1)\n",
    "y = tf.matmul(a, w2)\n",
    "\n",
    "sess = tf.Session()\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess.run(init_op)\n",
    "#如果不指定placeholder的取值，那么运行时将会报错\n",
    "#print(sess.run(y))\n",
    "\n",
    "# print(sess.run(y, feed_dict = {x:[[0.7,0.9]]}))  输出：[[ 3.95757794]]，x的shape为（1,2）\n",
    "print(sess.run(y, feed_dict = {x : [[0.7,0.9],[0.1,0.4],[0.5,0.8]]})) \n",
    "'''\n",
    "输出：\n",
    "[[ 3.95757794]\n",
    " [ 1.15376544]\n",
    " [ 3.16749239]]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.81131822  1.48459876  0.06532937]\n",
      " [-2.4427042   0.0992484   0.59122431]]\n",
      "[[-0.81131822]\n",
      " [ 1.48459876]\n",
      " [ 0.06532937]]\n",
      "After 0 training step(s), cross entropy onn all data is 1.89805\n",
      "After 1000 training step(s), cross entropy onn all data is 0.655075\n",
      "After 2000 training step(s), cross entropy onn all data is 0.626172\n",
      "After 3000 training step(s), cross entropy onn all data is 0.615096\n",
      "After 4000 training step(s), cross entropy onn all data is 0.610309\n",
      "[[ 0.02476984  0.5694868   1.69219422]\n",
      " [-2.19773483 -0.23668921  1.11438966]]\n",
      "[[-0.45544702]\n",
      " [ 0.49110931]\n",
      " [-0.9811033 ]]\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import RandomState\n",
    "\n",
    "#定义训练数据batch的大小\n",
    "batch_size = 8\n",
    "\n",
    "#定义神经网络参数。\n",
    "w1 = tf.Variable(tf.random_normal([2,3], stddev = 1, seed = 1))\n",
    "w2 = tf.Variable(tf.random_normal([3,1], stddev = 1, seed = 1))\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape = (None, 2), name = 'x-input')\n",
    "y_ = tf.placeholder(tf.float32, shape = (None, 1), name = 'y-input')\n",
    "\n",
    "#定义神经网络的前向传播过程\n",
    "\n",
    "a = tf.matmul(x, w1)\n",
    "y = tf.matmul(a, w2)\n",
    "\n",
    "# 反向传播算法\n",
    "y = tf.sigmoid(y)  # 使用sigmoid()函数将y转换为0~1的数值。y代表预测是正样本的概率，1-y代表预测是负样本的概率\n",
    "\n",
    "#定义损失函数来刻画预测值与真实值的差距\n",
    "cross_entropy = -tf.reduce_mean( y_ * tf.log(tf.clip_by_value(y, 1e-10, 1.0)) + (1 - y_) \\\n",
    "                                * tf.log(tf.clip_by_value(1-y, 1e-10, 1.0)))\n",
    "\n",
    "#定义学习率\n",
    "learning_rate = 0.001\n",
    "#定义反向传播算法用来优化神经网中的参数\n",
    "train_step = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy)\n",
    "\n",
    "    \n",
    "#通过一个随机数生成一个数据模拟器\n",
    "rdm = RandomState(1)\n",
    "dataset_size = 128\n",
    "X = rdm.rand(dataset_size, 2)\n",
    "Y = [[int(x1+x2 < 1)] for (x1,x2) in X]\n",
    "\n",
    "#创建一个会话来运行TensorFlow程序\n",
    "with tf.Session() as sess:\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    #初始化变量\n",
    "    sess.run(init_op)\n",
    "    \n",
    "    print(sess.run(w1))\n",
    "    print(sess.run(w2))\n",
    "    \n",
    "    #设定训练的轮数\n",
    "    STEPS = 5000\n",
    "    for i in range(STEPS):\n",
    "        start = (i * batch_size) % dataset_size\n",
    "        end = min(start+batch_size, dataset_size)\n",
    "        \n",
    "        sess.run(train_step, feed_dict = {x: X[start:end],y_: Y[start:end]})\n",
    "        \n",
    "        if i % 1000 == 0:\n",
    "            #每个一段时间计算所所有数据的交叉熵并输出\n",
    "            total_cross_entropy = sess.run(cross_entropy, feed_dict = {x: X, y_ : Y})\n",
    "            print(\"After %d training step(s), cross entropy onn all data is %g\" %(i, total_cross_entropy))\n",
    "    print(sess.run(w1))\n",
    "    print(sess.run(w2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
